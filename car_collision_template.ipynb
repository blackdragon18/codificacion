{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackdragon18/codificacion/blob/main/car_collision_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xbK5EqTvGv0"
      },
      "source": [
        "# CS 541-B Assignment 1(B):  Car collision\n",
        "\n",
        "#### Name: Ishaan Chawathe\n",
        "#### Stevens ID: 20031207"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFe0U5PcvX7B"
      },
      "source": [
        "You have been given a dataset containing the positions of two\n",
        "cars labeled as x1 and x2, along with a ground truth indicator y. In this context,\n",
        "y equals 0 if a collision occurs and 1 if there is no collision. Your task is to create\n",
        "a neural network capable of predicting collisions from scratch, without relying\n",
        "on pre-existing modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUUg-Ld9vHdR",
        "outputId": "27ebda43-0cdd-4808-b23d-1bdd8e06319a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-23 19:40:44--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_1/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48252 (47K) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  47.12K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-02-23 19:40:44 (3.87 MB/s) - ‘train.csv’ saved [48252/48252]\n",
            "\n",
            "--2025-02-23 19:40:44--  https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_1/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20695 (20K) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>]  20.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-23 19:40:44 (123 MB/s) - ‘test.csv’ saved [20695/20695]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Download the datset from the below link\n",
        "\"\"\"\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_1/train.csv'\n",
        "!wget 'https://raw.githubusercontent.com/liususan091219/cs541/main/hw1/prob2/dataset_1/test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P8_1BNBCveVg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, we are viewing more information about the dataset\n",
        "print(\"Training Data Info:\")\n",
        "print(df_train.info())\n",
        "print(df_train.describe())\n",
        "\n",
        "print(\"\\nTest Data Info:\")\n",
        "print(df_test.info())\n",
        "print(df_test.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_emr9euQT8EA",
        "outputId": "0cd40803-a23b-47c7-f86d-0dc6e9a68c55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3500 entries, 0 to 3499\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   x1      3500 non-null   float64\n",
            " 1   x2      3500 non-null   float64\n",
            " 2   y       3500 non-null   int64  \n",
            "dtypes: float64(2), int64(1)\n",
            "memory usage: 82.2 KB\n",
            "None\n",
            "                x1           x2            y\n",
            "count  3500.000000  3500.000000  3500.000000\n",
            "mean      2.466987     2.542629     0.823429\n",
            "std       1.447333     1.445768     0.381360\n",
            "min       0.001000     0.001000     0.000000\n",
            "25%       1.194250     1.290250     1.000000\n",
            "50%       2.515500     2.598500     1.000000\n",
            "75%       3.719000     3.784750     1.000000\n",
            "max       5.000000     5.000000     1.000000\n",
            "\n",
            "Test Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1500 entries, 0 to 1499\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   x1      1500 non-null   float64\n",
            " 1   x2      1500 non-null   float64\n",
            " 2   y       1500 non-null   int64  \n",
            "dtypes: float64(2), int64(1)\n",
            "memory usage: 35.3 KB\n",
            "None\n",
            "                x1           x2            y\n",
            "count  1500.000000  1500.000000  1500.000000\n",
            "mean      2.552796     2.491603     0.808000\n",
            "std       1.434703     1.447004     0.394004\n",
            "min       0.000000     0.001000     0.000000\n",
            "25%       1.286250     1.232500     1.000000\n",
            "50%       2.563000     2.510500     1.000000\n",
            "75%       3.787750     3.757000     1.000000\n",
            "max       4.994000     4.993000     1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZHHIVi12KTu",
        "outputId": "017e9986-54a6-4ef9-f8b0-ac7d228e95a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of training data:\n",
            "X_train: (3500, 2)\n",
            "y_train: (3500,)\n",
            "\n",
            "Shapes of test data:\n",
            "X_test: (1500, 2)\n",
            "y_test: (1500,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Extracting the features and label 'y'\n",
        "X_train = df_train.iloc[:, 0:2].values.astype('float32')\n",
        "y_train = df_train['y'].values.astype('float32')\n",
        "\n",
        "X_test = df_test.iloc[:, 0:2].values.astype('float32')\n",
        "y_test = df_test['y'].values.astype('float32')\n",
        "\n",
        "# Now, we are Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Viewing the shapes of Test and train data\n",
        "print(\"Shapes of training data:\")\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "\n",
        "print(\"\\nShapes of test data:\")\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"y_test:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA_fmvAnyQof"
      },
      "source": [
        "##Part-1 [15 pts]\n",
        "\n",
        "Implement a class of model, where in the init function, you can initialize the parameters of trainable weights like v11, v12, v21, v22, v31, v32, w1, w2. You can employ PyTorch to initialize them randomly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "class Car_collision:\n",
        "    def __init__(self):\n",
        "\n",
        "        #In our Neural Netwok Architeture, we are initializing the paramters of trainable weights\n",
        "        # For each hidden neuron, we have two weights (for x1 and x2) and one bias.\n",
        "\n",
        "        #This is the neuron 1 in Hidden layer\n",
        "        self.v11 = torch.randn(1, requires_grad=True)\n",
        "        self.v21 = torch.randn(1, requires_grad=True)\n",
        "        self.v31 = torch.randn(1, requires_grad=True)\n",
        "\n",
        "        #This is the neuron 2 in Hidden layer\n",
        "        self.v12 = torch.randn(1, requires_grad=True)\n",
        "        self.v22 = torch.randn(1, requires_grad=True)\n",
        "        self.v32 = torch.randn(1, requires_grad=True)\n",
        "\n",
        "        # Output layer weights from the two hidden neurons:\n",
        "        self.w1 = torch.randn(1, requires_grad=True)\n",
        "        self.w2 = torch.randn(1, requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # For the Forward pass, I have used x: a torch tensor of shape (2,)\n",
        "\n",
        "        if not isinstance(x, torch.Tensor):\n",
        "            x = torch.tensor(x, dtype=torch.float32)\n",
        "\n",
        "        # Below are the Hidden layer computations using ReLU acttivation function:\n",
        "        h1_linear = x[0] * self.v11 + x[1] * self.v21 + self.v31\n",
        "        h2_linear = x[0] * self.v12 + x[1] * self.v22 + self.v32\n",
        "        h1 = torch.relu(h1_linear)\n",
        "        h2 = torch.relu(h2_linear)\n",
        "\n",
        "        # Output layer is designed such that it calculaes a weighted sum followed by sigmoid activation function.\n",
        "        output_linear = h1 * self.w1 + h2 * self.w2\n",
        "        y_pred = torch.sigmoid(output_linear)\n",
        "        return y_pred\n",
        "\n",
        "    def parameters_list(self):\n",
        "        # Returning the list of all parameters for updating manually\n",
        "        return [self.v11, self.v21, self.v31, self.v12, self.v22, self.v32, self.w1, self.w2]\n",
        "\n",
        "model = Car_collision()\n"
      ],
      "metadata": {
        "id": "YmVag37vT3Q0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcKuMzfH45KS"
      },
      "source": [
        "##Part-2 [15 pts]\n",
        "Implement a training loop that iterates over all the data, computes the gradient scores, updates all weights defined in the Car_collision model, and calculates the average loss obtained from all iterations. You can choose best learning rate, and select epochs number"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#In the training loop, I have introduced momentum and velocity.\n",
        "#For every parameter, we maintain a \"velocity\" that accumulates past gradient information.\n",
        "#So, Instead of updating the parameter solely based on the current gradient, we update it using a running average of previous gradients. This accumulated value is called the velocity.\n",
        "#The momentum term determines how much of the previous velocity is retained in the current update.\n",
        "#By using momentum, the model remembers the direction of past updates. This helps it to move faster in correct gradient directions and also reduces oscillations.\n",
        "#Hence, this leads to faster convergence and a more stable training process.\n",
        "\n",
        "#By using these concepts, I have observed that there is a noticable increase in the accuracy value\n",
        "\n",
        "# Preparing the training samples\n",
        "train_samples = list(zip(X_train, y_train))\n",
        "\n",
        "learning_rate = 2e-4\n",
        "num_epochs = 30\n",
        "momentum = 0.9\n",
        "\n",
        "# Initializing velocity for each parameter\n",
        "velocities = [torch.zeros_like(param) for param in model.parameters_list()]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    for x_sample, y_true in train_samples:\n",
        "        x_tensor = torch.tensor(x_sample, dtype=torch.float32)\n",
        "\n",
        "        #forward pass\n",
        "        y_pred = model.forward(x_tensor)\n",
        "        y_true_tensor = torch.tensor([y_true], dtype=torch.float32)\n",
        "\n",
        "        # Calculating the binary cross entropy loss\n",
        "        loss = F.binary_cross_entropy(y_pred, y_true_tensor)\n",
        "\n",
        "        # Backward pass: calculating the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters with momentum\n",
        "        with torch.no_grad():\n",
        "            for i, param in enumerate(model.parameters_list()):\n",
        "                velocities[i] = momentum * velocities[i] - learning_rate * param.grad\n",
        "                param.add_(velocities[i])\n",
        "                param.grad.zero_()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_samples)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQF4OkyRUWsF",
        "outputId": "b4b3aa13-88d9-4398-f50a-9847a01a9e87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 0.4971\n",
            "Epoch 2/30, Loss: 0.4679\n",
            "Epoch 3/30, Loss: 0.4637\n",
            "Epoch 4/30, Loss: 0.4591\n",
            "Epoch 5/30, Loss: 0.4534\n",
            "Epoch 6/30, Loss: 0.4474\n",
            "Epoch 7/30, Loss: 0.4421\n",
            "Epoch 8/30, Loss: 0.4380\n",
            "Epoch 9/30, Loss: 0.4349\n",
            "Epoch 10/30, Loss: 0.4328\n",
            "Epoch 11/30, Loss: 0.4314\n",
            "Epoch 12/30, Loss: 0.4306\n",
            "Epoch 13/30, Loss: 0.4300\n",
            "Epoch 14/30, Loss: 0.4297\n",
            "Epoch 15/30, Loss: 0.4295\n",
            "Epoch 16/30, Loss: 0.4294\n",
            "Epoch 17/30, Loss: 0.4294\n",
            "Epoch 18/30, Loss: 0.4293\n",
            "Epoch 19/30, Loss: 0.4293\n",
            "Epoch 20/30, Loss: 0.4292\n",
            "Epoch 21/30, Loss: 0.4292\n",
            "Epoch 22/30, Loss: 0.4291\n",
            "Epoch 23/30, Loss: 0.4290\n",
            "Epoch 24/30, Loss: 0.4289\n",
            "Epoch 25/30, Loss: 0.4288\n",
            "Epoch 26/30, Loss: 0.4288\n",
            "Epoch 27/30, Loss: 0.4288\n",
            "Epoch 28/30, Loss: 0.4287\n",
            "Epoch 29/30, Loss: 0.4287\n",
            "Epoch 30/30, Loss: 0.4287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VotcOjeS5ny9"
      },
      "source": [
        "##Part-4 [5 pts]\n",
        "Implement a loop that iterates over all the test data, predicts scores, and assigns a value of 1 if the score is greater than 0.5, otherwise 0.\n",
        "\n",
        "\n",
        "Then calculate the test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the test samples\n",
        "test_samples = list(zip(X_test, y_test))\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x_sample, y_true in test_samples:\n",
        "        x_tensor = torch.tensor(x_sample, dtype=torch.float32)\n",
        "        #predicting the value\n",
        "        y_pred = model.forward(x_tensor)\n",
        "        # As per our condition, if the predicted label value is greater than threshold 0.5, there is no collision\n",
        "        pred_label = 1 if y_pred.item() > 0.5 else 0\n",
        "        if pred_label == int(y_true):\n",
        "            correct += 1\n",
        "        total += 1\n",
        "#Calculating the Test accuracy\n",
        "accuracy = (correct / total) * 100\n",
        "print(f\"Accuracy on test data: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkdYd707Ueap",
        "outputId": "89401915-00ff-4fda-ed4b-c37fd6bc404b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data: 81.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Accuracy report:**\n",
        "<pre>\n",
        "            Instructor's Accuracy     My Accuracy\n",
        "Dataset 1:      77.07%                 81.67%\n",
        "\n",
        "Dataset 2:      67.40%                 68.47%\n",
        "\n",
        "Dataset 3:      61.87%                 63.20%\n",
        "\n",
        "Dataset 4:      79.07%                 82.00%\n",
        "\n",
        "Dataset 5:      75.53%                 77.67%\n",
        "\n",
        "</pre>"
      ],
      "metadata": {
        "id": "GpkHqRJ8rqbI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}